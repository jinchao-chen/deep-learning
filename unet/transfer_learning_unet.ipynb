{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hs1g1ErHmenz"
   },
   "outputs": [],
   "source": [
    "# Install required libs\n",
    "%%capture\n",
    "! pip install segmentation-models-pytorch==0.1.2\n",
    "! pip install --upgrade albumentations\n",
    "! pip install catalyst\n",
    "! pip install pytorch_toolbelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "KIvPNVRsmen2",
    "outputId": "ab058d95-0c72-4cc5-de39-a66bc2ea62fd"
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from catalyst.contrib.nn import IoULoss, DiceLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOdslxCgmen3"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb3BEINumen4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeySWUTrZBu8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "import sys\n",
    "\n",
    "\n",
    "class Meter(object):\n",
    "    '''Meters provide a way to keep track of important statistics in an online manner.\n",
    "    This class is abstract, but provides a standard interface for all meters to follow.\n",
    "    '''\n",
    "\n",
    "    def reset(self):\n",
    "        '''Resets the meter to default settings.'''\n",
    "        pass\n",
    "\n",
    "    def add(self, value):\n",
    "        '''Log a new value to the meter\n",
    "        Args:\n",
    "            value: Next result to include.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def value(self):\n",
    "        '''Get the value of the meter in the current state.'''\n",
    "        pass\n",
    "\n",
    "\n",
    "class AverageValueMeter(Meter):\n",
    "    def __init__(self):\n",
    "        super(AverageValueMeter, self).__init__()\n",
    "        self.reset()\n",
    "        self.val = 0\n",
    "\n",
    "    def add(self, value, n=1):\n",
    "        self.val = value\n",
    "        self.sum += value\n",
    "        self.var += value * value\n",
    "        self.n += n\n",
    "\n",
    "        if self.n == 0:\n",
    "            self.mean, self.std = np.nan, np.nan\n",
    "        elif self.n == 1:\n",
    "            self.mean = 0.0 + self.sum  # This is to force a copy in torch/numpy\n",
    "            self.std = np.inf\n",
    "            self.mean_old = self.mean\n",
    "            self.m_s = 0.0\n",
    "        else:\n",
    "            self.mean = self.mean_old + (value - n * self.mean_old) / float(self.n)\n",
    "            self.m_s += (value - self.mean_old) * (value - self.mean)\n",
    "            self.mean_old = self.mean\n",
    "            self.std = np.sqrt(self.m_s / (self.n - 1.0))\n",
    "\n",
    "    def value(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "    def reset(self):\n",
    "        self.n = 0\n",
    "        self.sum = 0.0\n",
    "        self.var = 0.0\n",
    "        self.val = 0.0\n",
    "        self.mean = np.nan\n",
    "        self.mean_old = 0.0\n",
    "        self.m_s = 0.0\n",
    "        self.std = np.nan\n",
    "\n",
    "class Epoch:\n",
    "\n",
    "    def __init__(self, model, loss, metrics, stage_name, device='cpu', verbose=True):\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.stage_name = stage_name\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "\n",
    "        self._to_device()\n",
    "\n",
    "    def _to_device(self):\n",
    "        self.model.to(self.device)\n",
    "        self.loss.to(self.device)\n",
    "        for metric in self.metrics:\n",
    "            metric.to(self.device)\n",
    "\n",
    "    def _format_logs(self, logs):\n",
    "        str_logs = ['{} - {:.4}'.format(k, v) for k, v in logs.items()]\n",
    "        s = ', '.join(str_logs)\n",
    "        return s\n",
    "\n",
    "    def batch_update(self, x, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, dataloader):\n",
    "\n",
    "        self.on_epoch_start()\n",
    "\n",
    "        logs = {}\n",
    "        loss_meter = AverageValueMeter()\n",
    "        metrics_meters = {metric.__class__.__name__: AverageValueMeter() for metric in self.metrics}\n",
    "\n",
    "        with tqdm(dataloader, desc=self.stage_name, file=sys.stdout, disable=not (self.verbose)) as iterator:\n",
    "            for x, y in iterator:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                loss, y_pred = self.batch_update(x, y)\n",
    "\n",
    "                # update loss logs\n",
    "                loss_value = loss.cpu().detach().numpy()\n",
    "                loss_meter.add(loss_value)\n",
    "                loss_logs = {self.loss.__class__.__name__: loss_meter.mean}\n",
    "                logs.update(loss_logs)\n",
    "\n",
    "                # update metrics logs\n",
    "                for metric_fn in self.metrics:\n",
    "                    metric_value = metric_fn(y_pred, y).cpu().detach().numpy()\n",
    "                    metrics_meters[metric_fn.__class__.__name__].add(metric_value)\n",
    "                metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n",
    "                logs.update(metrics_logs)\n",
    "\n",
    "                if self.verbose:\n",
    "                    s = self._format_logs(logs)\n",
    "                    iterator.set_postfix_str(s)\n",
    "\n",
    "        return logs\n",
    "\n",
    "\n",
    "class TrainEpoch(Epoch):\n",
    "\n",
    "    def __init__(self, model, loss, metrics, optimizer, device='cpu', verbose=True):\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "            stage_name='train',\n",
    "            device=device,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        self.model.train()\n",
    "\n",
    "    def batch_update(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "        prediction = self.model.forward(x)\n",
    "        loss = self.loss(prediction, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss, prediction\n",
    "\n",
    "\n",
    "class ValidEpoch(Epoch):\n",
    "\n",
    "    def __init__(self, model, loss, metrics, device='cpu', verbose=True):\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "            stage_name='valid',\n",
    "            device=device,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        self.model.eval()\n",
    "\n",
    "    def batch_update(self, x, y):\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model.forward(x)\n",
    "            loss = self.loss(prediction, y)\n",
    "        return loss, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hld5xTPQmen4",
    "outputId": "7cbd384d-1276-44e4-ff90-027b5d1f32fa"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/data/'\n",
    "\n",
    "# load repo with data if it is not exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print('down load the data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haTHgkppBldo"
   },
   "source": [
    "## import noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ODFZWRXmen5"
   },
   "outputs": [],
   "source": [
    "x_train_dir = os.path.join(DATA_DIR, 'imgs/train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'masks/train')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'imgs/validation')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'masks/validation')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'imgs/test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'masks/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D5S_1fymen5"
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_vvC1wTmen5"
   },
   "source": [
    "### Dataloader\n",
    "\n",
    "Writing helper class for data extraction, tranformation and preprocessing  \n",
    "https://pytorch.org/docs/stable/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktPeF9T3men6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0F7XbuImen6"
   },
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['crop', 'weed']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "            transform = None,\n",
    "            drop_ids = None\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.ids = list(set(self.ids) - set(drop_ids)) \n",
    "        self.ids = self.ids[:10]\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        # self.images_fps.remove('./data/data/imgs/train/bonirob_2016-05-23-10-37-10_0_frame102.png')\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        # self.masks_fps.remove('./data/data/masks/train/bonirob_2016-05-23-10-37-10_0_frame102.png')\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [39, 78] #[self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        # print(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # To exclude transformation here. the transformation will be included at a later stage\n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        \n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        if mask.shape[-1] != 1:\n",
    "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "            mask = np.concatenate((mask, background), axis=-1)\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "      \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GS2OUZBpmen7"
   },
   "outputs": [],
   "source": [
    "# Lets look at data we have, and load all the data\n",
    "dataset = Dataset(x_train_dir, y_train_dir, classes=['crop', 'weed'], drop_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QSRw1O0men8"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1zeRlB2men9"
   },
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmmNcpf5men9"
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        albu.PadIfNeeded(min_height=1024, min_width=1024, always_apply=True, border_mode=0),\n",
    "        albu.RandomCrop(height=512, width=512, always_apply=True),\n",
    "\n",
    "        albu.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        albu.IAAPerspective(p=0.5),\n",
    "        \n",
    "        albu.CLAHE(p=0.5),\n",
    "        albu.RandomBrightness(p=0.5),\n",
    "        albu.RandomGamma(p=0.5),\n",
    "        \n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.IAASharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(384, 480)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDirFB1wmen_"
   },
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8PbNY6Amen_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A_I8-K1men_",
    "outputId": "9c08a132-bc4b-4484-fa8d-a634a5c6e259"
   },
   "outputs": [],
   "source": [
    "ENCODER = 'efficientnet-b4'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['A','B']\n",
    "ACTIVATION = 'softmax' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(\"The divice running is: \", DEVICE)\n",
    "\n",
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES)+1) # case for binary and multiclass segmentation\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes= n_classes, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ToFH7CugmeoA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=None, #get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    "    drop_ids=noise_flns_train\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=None, #get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    "    drop_ids=noise_flns_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oK9uaBymBb51"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_sample_weight \n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from pytorch_toolbelt.utils import fs\n",
    "\n",
    "def get_balanced_weights(dataset):\n",
    "    labels=[]\n",
    "    \n",
    "    for mask in dataset.masks_fps:\n",
    "        mask = fs.read_image_as_is(str(mask))\n",
    "        unique_labels = np.unique(mask)\n",
    "        labels.append(''.join([str(int(i)) for i in unique_labels]))\n",
    "        weights = compute_sample_weight('balanced', labels)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "mul_factor = 5\n",
    "train_sampler = WeightedRandomSampler(get_balanced_weights(train_dataset), len(train_dataset) * mul_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGzk8_TRBdmb"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, sampler= None )#train_sampler)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xMiiuCwokuZ"
   },
   "source": [
    "## loss function for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rjhht0S2xvwT"
   },
   "outputs": [],
   "source": [
    "loss = IoULoss(mode='weighted', weights=[0,0,1])\n",
    "\n",
    "metrics = [\n",
    "    DiceLoss(mode='macro'),\n",
    "    IoULoss(mode='macro')\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1ydFHL1CWqp"
   },
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UFNFz-2SmeoB",
    "outputId": "71c207f3-9030-48cf-f867-60886682849c"
   },
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "\n",
    "max_score = 1\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader,)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score > valid_logs['IoULoss']:\n",
    "        max_score = valid_logs['IoULoss']\n",
    "        torch.save(model, './best_model.pth')\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n",
    "\n",
    "    if i == 50:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-6\n",
    "        print('Decrease decoder learning rate to 1e-6!')\n",
    "\n",
    "    if i == 100:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-7\n",
    "        print('Decrease decoder learning rate to 1e-7!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axQILp4HmeoC"
   },
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_WcPMppmeoC"
   },
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "best_model = torch.load('./best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqxPh3vimeoC"
   },
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    "    drop_ids= noise_flns_train\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWyzN0ZCmeoD"
   },
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "test_epoch = ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Rov7JxMDZQG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "segmentation transfer learning - Unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
